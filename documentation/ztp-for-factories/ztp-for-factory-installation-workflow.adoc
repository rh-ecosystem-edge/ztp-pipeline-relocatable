[id="ztp-for-factory-installation-workflow"]
= The workflow
include::modules/common-attributes.adoc[]
:context: ztp-for-factory-installation-workflow

toc::[]

== OpenShift Pipelines installation

First, we need to install OpenShift Pipelines Operator that will be used for running the pipeline, this is achieved by using a bootstrapping script that will install the Operator and the CR to initiate the deployment.

This script, will also create the required pipeline definitions and tasks.


=== Bootstrapping OpenShift Pipelines and ZTPFW
- Execute the bootstrap script file `pipelines/bootstrap.sh ${KUBECONFIG}` you can do that using this command:

NOTE:: This bootstrap script will require at least these binaries: oc, yq, tkn

```sh
export KUBECONFIG=/root/.kcli/clusters/test-ci/auth/kubeconfig
curl -sLk https://raw.githubusercontent.com/rh-ecosystem-edge/ztp-pipeline-relocatable/main/pipelines/bootstrap.sh | bash -s
```

- An  output similar to this one, will be shown:

```console
>>>> Creating NS edgecluster-deployer and giving permissions to SA edgecluster-deployer
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
namespace/edgecluster-deployer configured
serviceaccount/edgecluster-deployer configured
clusterrolebinding.rbac.authorization.k8s.io/cluster-admin-0 configured

>>>> Cloning Repository into your local folder
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Cloning into 'ztp-pipeline-relocatable'...
remote: Enumerating objects: 3824, done.
remote: Counting objects: 100% (1581/1581), done.
remote: Compressing objects: 100% (963/963), done.
remote: Total 3824 (delta 963), reused 1163 (delta 589), pack-reused 2243
Receiving objects: 100% (3824/3824), 702.12 KiB | 8.46 MiB/s, done.
Resolving deltas: 100% (2182/2182), done.

>>>> Deploying OpenShift Pipelines
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
subscription.operators.coreos.com/openshift-pipelines-operator-rh unchanged
>>>> Waiting for: OpenShift Pipelines
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>> Deploying ZTPFW Pipelines and tasks
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
pipeline.tekton.dev/deploy-ztp-hub configured
pipeline.tekton.dev/deploy-ztp-edgeclusters configured
task.tekton.dev/common-pre-flight configured
task.tekton.dev/hub-deploy-mce configured
task.tekton.dev/hub-deploy-disconnected-registry configured
task.tekton.dev/hub-deploy-httpd-server configured
task.tekton.dev/hub-deploy-hub-config configured
task.tekton.dev/hub-deploy-icsp-hub configured
task.tekton.dev/hub-save-config configured
task.tekton.dev/edgecluster-deploy-disconnected-registry-edgeclusters configured
task.tekton.dev/edgecluster-deploy-icsp-edgeclusters-post configured
task.tekton.dev/edgecluster-deploy-icsp-edgeclusters-pre configured
task.tekton.dev/edgecluster-deploy-metallb configured
task.tekton.dev/edgecluster-deploy-odf configured
task.tekton.dev/edgecluster-deploy-edgecluster configured
task.tekton.dev/edgecluster-deploy-workers configured
task.tekton.dev/edgecluster-detach-cluster configured
task.tekton.dev/edgecluster-restore-hub-config configured
```

This script will deploy OpenShift-Pipelines and enable the Tasks and Pipelines in the Hub cluster under the `edgecluster-deployer` Namespace.

We can now continue the flow using either the command line or the UI to interact with OpenShift Pipelines. To interact with OpenShift Pipelines using CLI, it is recommended to install the Tekton CLI `tkn` from this https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/pipeline/latest/tkn-linux-amd64-0.21.0.tar.gz[link].

== ZTPFW Pipelines

We have 2 Pipelines created composed by some tasks each ones. Every Pipeline will be properly documented in each section.

Let's explain the pipeline arguments and Flags we use in the ZTPFW, for that we will use this sample command as a base:

```sh
tkn pipeline start -n edgecluster-deployer -p ztp-container-image="quay.io/ztpfw/pipeline:main" -p edgeclusters-config="$(cat /root/amorgant/ztp-pipeline-relocatable/hack/deploy-hub-local/edgeclusters.yaml)" -p kubeconfig=${KUBECONFIG} -w name=ztp,claimName=ztp-pvc --timeout 5h --use-param-defaults deploy-ztp-hub
```

.Pipeline Flags
|===
|Flag/Section | Description

| `-n`
| OpenShift Namespace where the resources will be located

| `-p`
| Pipeline Parameter

| `--timeout`
| Pipeline General timeout.

| `--use-param-defaults`
| This means, "Apart of the parameters provided, the rest ones use the default options"

| `-w`
| The `Workspace` parameter sets where OpenShift Pipelines will hold the files during every step. We should not use `EmptyDir`.  If we use `EmptyDir`, the files generated between steps will not be saved. The best choice is `name=ztp,claimName=ztp-pvc`. The PVC will be created during the `bootstrap.sh` execution (It does not need more than 5Gb).
|===

.Pipeline Arguments
|===
|Parameter/Section | Description | Required

| [[Namespace]] `Namespace`
| This is a Namespace where all the Tasks and Pipelines will be deployed.
| Yes

| [[git-revision]] `git-revision`
| This will download the ZTPFW code from a concrete branch. This optional argument can be used for testing changes. Default: `main`
| No

| [[edgeclusters-config]] `edgeclusters-config`
| This `edgeclusters.yaml` file will contain the configuration for all the clusters you want to deploy at the same time. You need to put it with a `cat` command as we do in the example execution.
| Yes

| [[kubeconfig]] `kubeconfig`
| This is the **Hub** kubeconfig that will be used during the pipeline execution. You can point to the file or just use the KUBECONFIG variable.
| Yes

| `-w name=ztp,claimName=ztp-pvc`
| It is mandatory to use this argument exactly as it's shown here to have a successfull run. With this declaration we are telling Tekton to use the Workspace ztp and the content should be placed in the `ztp-pvc` Persistent Volume.
| Yes

| `Pipeline Name`
| In our example command, it's the last argument. We instruct Tekton to execute the Pipeline with the particular name. You can look at the executed Pipelines and/or Tasks with `tkn pr ls` or `tkn task ls` respectively.
| Yes
|===

The above command will trigger the Pipeline. It's asynchronous and its output can be examined with `tkn pr logs <pipelinerun name>`.

include::ztp-for-factory-pipeline-hub.adoc[leveloffset=+1]
include::ztp-for-factory-pipeline-edge.adoc[leveloffset=+1]

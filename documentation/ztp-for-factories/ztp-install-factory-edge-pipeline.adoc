// Module included in the following assemblies:
//
// * scalability_and_performance/ztp-factory-install-clusters.adoc
:_content-type: PROCEDURE
[id="running-the-edge-cluster_factory_install_pipeline_{context}"]
= Running the edge cluster factory install pipeline
include::modules/common-attributes.adoc[]

Run the following steps to run the edge factory install pipeline.

.Prerequisites

* Enough free IPs in the external network DHCP's range for the edge cluster.
* The following API, API-INT and ingress entries are resolvable:
** `api.<edge-cluster-name>.<network-domain>`
** `api-int.<edge-cluster-name>.<network-domain>`
** `*.apps.<edge-cluster-name>.<network-domain>`

[NOTE]
====
When deploying a single-node OpenShift cluster, the `api.<edge-cluster-name>.<baseDomain>` and `*.apps.<edge-cluster-name>.<baseDomain>` must be configured with different IP addresses.
====

* Clean disks for the OpenShift Data Foundation Storage cluster.
* An {product-title} hub cluster.
* DNS Resolution between the edge and the hub API and ingress entries.
* Log in as a user with `cluster-admin` privileges.

.Procedure

. Edit the `edgeclusters.yaml` with sample details as shown. A sample configuration file is present in `examples/config.yaml`.
+
[NOTE]
====
At this stage you are populating the `edgeclusters` section.
====
+
[source,yaml]
----
config:
  OC_OCP_VERSION: "4.10.24"
  OC_ACM_VERSION: "2.5"
  OC_ODF_VERSION: "4.10"

edgeclusters:
  - edgecluster1-name: <1>
      contrib:
        gpu-operator:
          version: "v1.9.0"
      master0: <2>
        ignore_ifaces: eno1,eno2 <3>
        nic_ext_dhcp: eno4 <4>
        nic_int_static: eno5 <5>
        mac_ext_dhcp: "aa:ss:dd:ee:b0:10" <6>
        mac_int_static: "aa:ss:dd:ee:b1:10" <7>
        bmc_url: "<url bmc>" <8>
        bmc_user: "user-bmc" <9>
        bmc_pass: "user-pass" <10>
        root_disk: sda <11>
        storage_disk: <12>
          - sdb
          - sdc
          - sde
          - sdd
      master1:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static: eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:11"
        mac_int_static: "aa:ss:dd:ee:b1:11"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: sda
        storage_disk:
          - sdb
          - sdc
          - sde
          - sdd
      master2:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static: eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:12"
        mac_int_static: "aa:ss:dd:ee:b1:12"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: sda
        storage_disk:
          - sdb
          - sdc
          - sde
          - sdd
    worker0: <13>
        nic_ext_dhcp: eno4
        nic_int_static: eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:19"
        mac_int_static: "aa:ss:dd:ee:b1:19"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: sda
  - edgecluster2-name:
      master0:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:20"
        mac_int_static: "aa:ss:dd:ee:b1:20"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: sda
        storage_disk:
          - sdb
          - sdc
          - sde
          - sdd
      master1:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:21"
        mac_int_static: "aa:ss:dd:ee:b1:21"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: sda
        storage_disk:
          - sdb
          - sdc
          - sde
          - sdd
      master2:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:22"
        mac_int_static: "aa:ss:dd:ee:b1:22"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: sda
        storage_disk:
          - sdb
          - sdc
          - sde
          - sdd
      worker0:
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:29"
        mac_int_static: "aa:ss:dd:ee:b1:29"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: sda
----
<1> This option is configurable and sets the name of the edge cluster.
<2> This value must match `master0`, `master1` or `master2`.
<3> Optional: Interfaces to ignore in the host.
<4> NIC connected to the external DHCP.
<5> NIC connected to the internal network (This interface is optional).
<6> MAC address for the NIC connected to the external DHCP network.
<7> MAC address for the NIC connected to the internal network (This MAC address is optional if we're using only 1 interface nic in <5>).
<8> URL for the Baseboard Management Controller (BMC).
<9> The BMC username.
<10> The BMC password.
<11> Mandatory: Disk device to be used for operating system installation.
<12> List of disk available in the node to be used for storage.
<13> Hardcoded name set as `worker0` for the worker node.

. Set the following environment variable:
+
[source,terminal]
----
$ export KUBECONFIG=<path_to_kubeconfig>/kubeconfig-file
----

. Start the edge cluster pipeline from the command line:
+
[source,terminal]
----
$ tkn pipeline start -n edgecluster-deployer edgeclusters-config="$(cat /path-to-edgecluster-yaml/edgeclusters.yaml)" -p kubeconfig=${KUBECONFIG} -w=ztp,claimName=ztp-pvc --timeout 5h --use-param-defaults deploy-ztp-edgeclusters
----
+
[NOTE]
====
This command starts the pipeline in the namespace `edgecluster-deployer` with the defined configuration and the `kubeconfig`  in the workspace ztp with the previously configured persistent storage claim `ztp-pvc`. A timeout of 5 hours is set for the execution of the `deploy-ztp-edgeclusters` with all other parameters set to the default.
====
+
.Example output
+
[source,terminal]
----
PipelineRun started: deploy-ztp-edgecluster-run-2rklt

In order to track the PipelineRun progress run:
tkn pipeline logs deploy-ztp-edgecluster-run-2rklt -f -n edgecluster-deployer
----

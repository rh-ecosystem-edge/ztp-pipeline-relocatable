// Module included in the following assemblies:
//
// * scalability_and_performance/ztp-factory-install-clusters.adoc
:_content-type: PROCEDURE
[id="running-the-edge-cluster_factory_install_pipeline_{context}"]
= Running the edge cluster factory install pipeline
include::modules/common-attributes.adoc[]

Follow the steps in this section to run the edge factory install pipeline.

.Prerequisites

* The external network's DHCP range should have enough IPs for the edge cluster.
* The following API, API-INT and ingress DNS entries are resolvable:
** `api.<edge-cluster-name>.<network-domain>`
** `api-int.<edge-cluster-name>.<network-domain>`
** `*.apps.<edge-cluster-name>.<network-domain>`

[NOTE]
====
When deploying a single-node OpenShift cluster, the `api.<edge-cluster-name>.<baseDomain>` and `*.apps.<edge-cluster-name>.<baseDomain>` must be configured with different IP addresses.
====

* Clean disks for the OpenShift Data Foundation Storage cluster.
* An {product-title} hub cluster.
* DNS Resolution between the edge and the hub API and ingress entries.
* Log in as a user with `cluster-admin` privileges.

.Procedure

. Edit the `edgeclusters.yaml` with sample details as shown. A sample configuration file is present in `examples/config.yaml`.
+
[NOTE]
====
At this stage you are populating the `edgeclusters` section.
====
+
[source,yaml]
----
config:
  OC_OCP_VERSION: "4.10.38"
  OC_ACM_VERSION: "2.5"
  OC_ODF_VERSION: "4.10"
  REGISTRY: myregistry.local:5000  <1>

edgeclusters:
  - edgecluster1-name: <2>
      config:
        tpm: false
      master0: <3>
        ignore_ifaces: eno1,eno2 <4>
        nic_ext_dhcp: eno4 <5>
        nic_int_static: eno5 <6>
        mac_ext_dhcp: "aa:ss:dd:ee:b0:10" <7>
        mac_int_static: "aa:ss:dd:ee:b1:10" <8>
        bmc_url: "<url bmc>" <9>
        bmc_user: "user-bmc" <10>
        bmc_pass: "user-pass" <11>
        root_disk: /dev/sda <12>
        storage_disk: <13>
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
      master1:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static: eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:11"
        mac_int_static: "aa:ss:dd:ee:b1:11"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: /dev/sda
        storage_disk:
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
      master2:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static: eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:12"
        mac_int_static: "aa:ss:dd:ee:b1:12"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: /dev/sda
        storage_disk:
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
    worker0: <14>
        nic_ext_dhcp: eno4
        nic_int_static: eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:19"
        mac_int_static: "aa:ss:dd:ee:b1:19"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: /dev/sda
        storage_disk:
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
  - edgecluster2-name:
      master0:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:20"
        mac_int_static: "aa:ss:dd:ee:b1:20"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: /dev/sda
        storage_disk:
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
      master1:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:21"
        mac_int_static: "aa:ss:dd:ee:b1:21"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: /dev/sda
        storage_disk:
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
      master2:
        ignore_ifaces: eno1 eno2
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:22"
        mac_int_static: "aa:ss:dd:ee:b1:22"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: /dev/sda
        storage_disk:
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
      worker0:
        nic_ext_dhcp: eno4
        nic_int_static:  eno5
        mac_ext_dhcp: "aa:ss:dd:ee:b0:29"
        mac_int_static: "aa:ss:dd:ee:b1:29"
        bmc_url: "<url bmc>"
        bmc_user: "user-bmc"
        bmc_pass: "user-pass"
        root_disk: /dev/sda
        storage_disk:
          - /dev/sdb
          - /dev/sdc
          - /dev/sde
          - /dev/sdd
----
<1> This parameter is optional just in case you want to use your own registry already deployed. Remember, if you are using your own registry, the pull secret must contains the information related to the entry (url, username and password)
<2> This option is configurable and sets the name of the edge cluster.
<3> This value must match `master0`, `master1` or `master2`.
<4> Optional: Interfaces to ignore in the host.
<5> NIC connected to the external DHCP.
<6> NIC connected to the internal network (This interface is optional).
<7> MAC address for the NIC connected to the external DHCP network.
<8> MAC address for the NIC connected to the internal network (This MAC address is optional if we're using only 1 interface nic in <5>).
<9> URL for the Baseboard Management Controller (BMC).
<10> The BMC username.
<11> The BMC password.
<12> Mandatory: Disk device to be used for operating system installation.
<13> List of disk available in the node to be used for storage.
<14> Hardcoded name set as `worker0` for the worker node.

. Set the following environment variable:
+
[source,terminal]
----
$ export KUBECONFIG=<path_to_kubeconfig>/kubeconfig-file
----

. Start the edge cluster pipeline from the command line:
+
[source,terminal]
----
$ tkn pipeline start \
-n edgecluster-deployer \
-p edgeclusters-config="$(cat /path-to-edgecluster-yaml/edgeclusters.yaml)" \
-p kubeconfig=${KUBECONFIG} \
-w name=ztp,claimName=ztp-pvc \
--timeout 5h \
--use-param-defaults \
deploy-ztp-edgeclusters
----
+
[NOTE]
====
This command starts the pipeline in the namespace `edgecluster-deployer` with the defined configuration and the `kubeconfig` configuration in the workspace ztp with the previously configured persistent storage claim `ztp-pvc`. A timeout of 5 hours is set for the execution of the `deploy-ztp-edgecluster` pipeline with all other parameters set to default.
====
+
.Example output
+
[source,terminal]
----
PipelineRun started: deploy-ztp-edgecluster-run-2rklt

In order to track the PipelineRun progress run:
tkn pipeline logs deploy-ztp-edgecluster-run-2rklt -f -n edgecluster-deployer
----

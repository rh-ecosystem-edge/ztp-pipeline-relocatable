[id="ztp-for-factory-prerequisites"]
= Prerequisites
include::modules/common-attributes.adoc[]
:context: ztp-for-factory-prerequisites

toc::[]

Installer-provisioned installation of {product-title} requires:

== Base
- OpenShift Cluster with 3 masters
    . All Cluster Operators in good health status
    . Cluster reachable via a `KUBECONFIG` file
    . The API/API-INT/Ingress should be deployed on the DHCP Ext Network (Factory network)

== Networking
- DNS entries configured and resolvable from both internal and external network, with DNS on the DHCP Factory network
    - HUB
        . `api.<hub-domain>.<domain>` and `api-int.<hub-domain>.<domain>` entries to the same IP address
        . ingress (*.apps.<hub-domain>.<net-domain>)
    - SPOKE
        . `api.<spoke-domain>.<net-domain>` and `api-int.<spoke-domain>.<net-domain>` entries to the same IP address
        . ingress (*.apps.<spoke-domain>.<net-domain>)
- External DHCP with some free IPs on the factory to provide access to the Spoke using the external network interface
    - Every Spoke will need at least ~6 IPs from this External Network (without the broadcast and network ip)
        . 1 per node
        . 1 API and same for API-INT
        . 1 for the Ingress entry (*.apps.<spoke-domain>.<net-domain>)

== Storage
- We need some existing PVs on the HUB
    NOTE:: We cannot use `emptyDir` directive for runninng the pipeline, because between each step in the pipeline the contents will be removed and we require them to further progress.
    . 3 PVs for ACM (the expected size will depend on how many spokes will you deploy)
    . 1 for the Hub Internal Registry, the base installation (which includes ACM, MetalLB, OCP version 4.X, NMState and some more images) we will need at least 200Gb on the Hub
    side (Maybe more if you have ODF/OCS deployed).
    . 1 for the HTTPD server, which will host the RHCOS images.
    . We need to meet the OpenShift Storage requirements for the Hub like (SSD/NVME).
    . LSO should be enough but we recommend to use a more reliable storage backend like ODF or NFS in order to avoid issues with the PVs and node scheduling pods.

== General
- `spokes.yaml` file with the configuration for the spokes (In this initial version you will need to bake this file by hand)
- The enclosure is suppose to be just one Spoke which contains 3 masters, 1 worker and 1 Switch L2-L3

Of course, the requirements for the installation of {product-title} are also to be satisfied on the hardware involved in the installation.

== The Spokes YAML file

The ```spokes.yaml``` file contains all the configuration information required about the setup.

There's an example in the repo at <https://raw.githubusercontent.com/rh-ecosystem-edge/ztp-pipeline-relocatable/main/examples/config.yaml>

As you can check, it has two major sections `config` and `spokes` that will be explained in the next section.

Just keep in mind that the spokes section, can contain several `spoke-name` entries, one per spoke cluster to be deployed by the workflow.

=== Spokes.yaml walktrough

Check next table for  a commented configuration file with links to the explanation to each relevant file section and configuration value.

[source,yaml, subs="verbatim,macros,attributes"]
ifdef::backend-pdf[[listing]]
----
ifeval::[{product-version} >= 1.0]
include::ztp-for-factory-spokes-yaml.adoc[]
endif::[]
----


.Required parameters
|===
|Parameter/Section | Description


| [[config]] `config`
| This section marks the cluster configuration values that will be used for installation or configuration in both Hub and Spokes.

| [[clusterimageset]] `clusterimageset`
| This setting defines the Cluster Image Set used for the HUB and the Spokes

| [[OC_OCP_VERSION]] `OC_OCP_VERSION`
| Defines the OpenShift version to be used for the installation.

| [[OC_OCP_TAG]] `OC_OCP_TAG`
| This setting defines version tag to use

| [[OC_RHCOS_RELEASE]] `OC_RHCOS_RELEASE`
| This is the release to be used

| [[OC_ACM_VERSION]] `OC_ACM_VERSION`
| Specifies which ACM version should be used for the deployment

| [[OC_OCS_VERSION]] `OC_OCS_VERSION`
| This defines the OCS version to be used

| [[spokes]] `spokes`
| This section is the one containing the configuration for each one of the Spoke Clusters


|[[spokename]] `spokename`
| This option is configurable and will be the name to be used for the spoke cluster

|[[mastername]] `mastername`
| This value must match `master0`, `master1` or `master2`.

|[[ignore_ifaces]] `ignore_ifaces`
| (Optional) Interfaces to ignore in the host

|[[nic_ext_dhcp]] `nic_ext_dhcp`
| NIC connected to the external DHCP

|[[nic_int_static]] `nic_int_static`
| NIC interface name connected to the internal network

|[[mac_ext_dhcp]] `mac_ext_dhcp`
| MAC Address for the NIC connected to the external DHCP network

|[[mac_int_static]] `mac_int_static`
| MAC Address for the NIC connected to the internal static network

|[[bmc_url]] `bmc_url`
| URL for the Baseboard Management Controller

|[[bmc_user]] `bmc_user`
| Username for the BMC

|[[bmc_pass]] `bmc_pass`
| Password for the BMC

|[[root_disk]] `root_disk`
| Mandatory: Disk device to be used for OS installation

|[[storage_disk]] `storage_disk`
| List of disk available in the node to be used for storage

|[[workername]] `workername`
| Hardcoded name as `worker0` for the worker node

|===

.Optional parameters
|===
|Parameter/Section | Description

| [[REGISTRY]] `REGISTRY`
| Use private registry. Specify in `<URL>:<PORT>`` format. 

|===

=== Private regisrty
By Default, The `ZTPFW` will deploy its own registry within the `HUB` cluster. Although, you can use your own registry.

First, verify that the `HUB` cluster contains the private registry credentials.

`oc get secret -n openshift-config pull-secret -ojsonpath='{.data.\.dockerconfigjson}' | base64 -d`

than modify the `config.yaml` with the URL for the repo

```yaml
# config.yaml
config:
    REGISTRY: my-registry.domain.local:5000

```

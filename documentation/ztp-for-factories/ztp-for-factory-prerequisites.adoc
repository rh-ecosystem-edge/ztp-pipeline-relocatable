[id="ztp-for-factory-prerequisites"]
= Prerequisites
include::modules/common-attributes.adoc[]
:context: ztp-for-factory-prerequisites

toc::[]

Installer-provisioned installation of {product-title} requires:

== Base
- OpenShift Cluster with 3 masters
    . All Cluster Operators in good health status
    . Cluster reachable via a `KUBECONFIG` file
    . The API/API-INT/Ingress should be deployed on the DHCP Ext Network (Factory network)

== Networking
- DNS entries configured and resolvable from both internal and external network, with DNS on the DHCP Factory network
    - HUB
        . `api.<hub-domain>.<domain>` and `api-int.<hub-domain>.<domain>` entries to the same IP address
        . ingress (*.apps.<hub-domain>.<net-domain>)
    - EDGE
        . `api.<edgecluster-domain>.<net-domain>` and `api-int.<edgecluster-domain>.<net-domain>` entries to the same IP address
        . ingress (*.apps.<edgecluster-domain>.<net-domain>)
- External DHCP with some free IPs on the factory to provide access to the Edge-cluster using the external network interface
    - Every Edge-cluster will need at least ~6 IPs from this External Network (without the broadcast and network IP)
        . 1 per node
        . 1 API and same for API-INT
        . 1 for the Ingress entry (*.apps.<edgecluster-domain>.<net-domain>)

== Storage
- We need some existing PVs on the HUB
    NOTE:: We cannot use `emptyDir` directive for runninng the pipeline, because between each step in the pipeline the contents will be removed and we require them to further progress.
    . 3 PVs for ACM (the expected size will depend on how many edgeclusters will you deploy)
    . 1 for the Hub Internal Registry, the base installation (which includes ACM, MetalLB, OCP version 4.X, NMState and some more images) we will need at least 200Gb on the Hub
    side (Maybe more if you have OCS/ODF deployed).
    . 1 for the HTTPD server, which will host the RHCOS images.
    . We need to meet the OpenShift Storage requirements for the Hub like (SSD/NVME).
    . LSO should be enough but we recommend to use a more reliable storage backend like ODF or NFS in order to avoid issues with the PVs and node scheduling pods.

== General
- `edgeclusters.yaml` file with the configuration for the edgeclusters (In this initial version you will need to bake this file by hand)
- The enclosure is suppose to be just one Edge-cluster which contains 3 masters, 1 worker and 1 Switch L2-L3

Of course, the requirements for the installation of {product-title} are also to be satisfied on the hardware involved in the installation.

== The Edge-clusters YAML file

The ```edgeclusters.yaml``` file contains all the configuration information required about the setup.

There's an example in the repo at <https://raw.githubusercontent.com/rh-ecosystem-edge/ztp-pipeline-relocatable/main/examples/config.yaml>

As you can check, it has two major sections `config` and `edgeclusters` that will be explained in the next section.

Just keep in mind that the edgeclusters section, can contain several `edgecluster-name` entries, one per edgecluster cluster to be deployed by the workflow.

=== Edge-clusters.yaml walktrough

Check next table for  a commented configuration file with links to the explanation to each relevant file section and configuration value.

[source,yaml, subs="verbatim,macros,attributes"]
ifdef::backend-pdf[[listing]]
----
ifeval::[{product-version} >= 1.0]
include::ztp-for-factory-edgeclusters-yaml.adoc[]
endif::[]
----


.Required parameters
|===
|Parameter/Section | Description


| [[config]] `config`
| This section marks the cluster configuration values that will be used for installation or configuration in both Hub and Edge-clusters.

| [[clusterimageset]] `clusterimageset`
| This setting defines the Cluster Image Set used for the HUB and the Edge-clusters

| [[OC_OCP_VERSION]] `OC_OCP_VERSION`
| Defines the OpenShift version to be used for the installation.

| [[OC_OCP_TAG]] `OC_OCP_TAG`
| This setting defines version tag to use

| [[OC_RHCOS_RELEASE]] `OC_RHCOS_RELEASE`
| This is the release to be used

| [[OC_ACM_VERSION]] `OC_ACM_VERSION`
| Specifies which ACM version should be used for the deployment

| [[OC_ODF_VERSION]] `OC_ODF_VERSION`
| This defines the ODF version to be used

| [[edgeclusters]] `edgeclusters`
| This section is the one containing the configuration for each one of the Edge-cluster Clusters


|[[edgeclustername]] `edgeclustername`
| This option is configurable and will be the name to be used for the edgecluster cluster

|[[mastername]] `mastername`
| This value must match `master0`, `master1` or `master2`.

|[[ignore_ifaces]] `ignore_ifaces`
| (Optional) Interfaces to ignore in the host

|[[nic_ext_dhcp]] `nic_ext_dhcp`
| NIC connected to the external DHCP

|[[nic_int_static]] `nic_int_static`
| NIC interface name connected to the internal network

|[[mac_ext_dhcp]] `mac_ext_dhcp`
| MAC Address for the NIC connected to the external DHCP network

|[[mac_int_static]] `mac_int_static`
| MAC Address for the NIC connected to the internal static network

|[[bmc_url]] `bmc_url`
| URL for the Baseboard Management Controller

|[[bmc_user]] `bmc_user`
| Username for the BMC

|[[bmc_pass]] `bmc_pass`
| Password for the BMC

|[[root_disk]] `root_disk`
| Mandatory: Disk device to be used for OS installation

|[[storage_disk]] `storage_disk`
| List of disk available in the node to be used for storage

|[[workername]] `workername`
| Hardcoded name as `worker0` for the worker node

|===
